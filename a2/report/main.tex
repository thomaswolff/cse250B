% Use only LaTeX2e, calling the article.cls class and 12-point type.

\documentclass[12pt]{article}

% Users of the {thebibliography} environment or BibTeX should use the
% scicite.sty package, downloadable from *Science* at
% www.sciencemag.org/about/authors/prep/TeX_help/ .
% This package should properly format in-text
% reference calls and reference-list numbers.

%\usepackage{scicite}

% Use times if you have the font installed; otherwise, comment out the
% following line.

\usepackage{times}

% The preamble here sets up a lot of new/revised commands and
% environments.  It's annoying, but please do *not* try to strip these
% out into a separate .sty file (which could lead to the loss of some
% information when we convert the file to other formats).  Instead, keep
% them in the preamble of your main LaTeX source file.


% The following parameters seem to provide a reasonable page setup.

\topmargin 0.0cm
\oddsidemargin 0.2cm
\textwidth 16cm 
\textheight 21cm
\footskip 1.0cm

%The next command sets up an environment for the abstract to your paper.

\newenvironment{sciabstract}{%
\begin{quote} \bf}
{\end{quote}}


% If your reference list includes text notes as well as references,
% include the following line; otherwise, comment it out.

\renewcommand\refname{References and Notes}

% The following lines set up an environment for the last note in the
% reference list, which commonly includes acknowledgments of funding,
% help, etc.  It's intended for users of BibTeX or the {thebibliography}
% environment.  Users who are hand-coding their references at the end
% using a list environment such as {enumerate} can simply add another
% item at the end, and it will be numbered automatically.

\newcounter{lastnote}
\newenvironment{scilastnote}{%
\setcounter{lastnote}{\value{enumiv}}%
\addtocounter{lastnote}{+1}%
\begin{list}%
{\arabic{lastnote}.}
{\setlength{\leftmargin}{.22in}}
{\setlength{\labelsep}{.5em}}}
{\end{list}}


% Include your paper's title here

\title{CSE 250B - Project 2} 


% Place the author information here.  Please hand-code the contact
% information and notecalls; do *not* use \footnote commands.  Let the
% author contact information appear immediately below the author names
% as shown.  We would also prefer that you don't change the type-size
% settings shown here.

\author
{Sigurd Lund,$^{\ast}$ Thomas Wolff$^{}$$\\
%\\
%\normalsize{$^{1}$Department of Chemistry, University of Wherever,}\\
%\normalsize{An Unknown Address, Wherever, ST 00000, USA}\\
%\normalsize{$^{2}$Another Unknown Address, Palookaville, ST 99999, USA}\\
%\\
\normalsize{$^\ast$To whom correspondence should be addressed; E-mail:  sigurd.l@gmail.com.}
}

% Include the date command, but leave its argument blank.

\date{}



%%%%%%%%%%%%%%%%% END OF PREAMBLE %%%%%%%%%%%%%%%%



\begin{document} 

% Double-space the manuscript.

\baselineskip24pt

% Make the title.

\maketitle 



% Place your abstract within the special {sciabstract} environment.

\begin{sciabstract}
  This document presents a number of hints about how to set up your
  {\it Science\/} paper in \LaTeX\ .  We provide a template file,
  \texttt{scifile.tex}, that you can use to set up the \LaTeX\ source
  for your article.  An example of the style is the special
  \texttt{\{sciabstract\}} environment used to set up the abstract you
  see here.
\end{sciabstract}



% In setting up this template for *Science* papers, we've used both
% the \section* command and the \paragraph* command for topical
% divisions.  Which you use will of course depend on the type of paper
% you're writing.  Review Articles tend to have displayed headings, for
% which \section* is more appropriate; Research Articles, when they have
% formal topical divisions at all, tend to signal them with bold text
% that runs into the paragraph, for which \paragraph* is the right
% choice.  Either way, use the asterisk (*) modifier, as shown, to
% suppress numbering.

\section*{Introduction}
In a team of two students, we conducted a project whose goal was to learn a conditional random field (CRF) model, that can add punctation (commas, exclamation marks, etc.) to English sentences in which the punctation is absent. The intended application is for typing on a smartphone, where the keyboard may be too small to show letters and punctation simultaneously. A user should only need to type in the words of a sentence, and the punctation will be automatically added by the software.

For this paper we will learn a model and test the accuracy on a given dataset, that consist of English sentences with punctation, taken from email messages.

The model is learned by using two different training algorithms: Collins' perception, and Gibbs sampling with contrastive divergence. Both uses feature functions to learn the model, and the trainers task is to assign weights to these functions. These learned weights will then be used to map a sentence to a sequence of punctation tags. A variation of the Viterbi algorithm are used for computing this sequence. 

Both training algorithms resulted in a accuracy rate between XXXXX. The algorithms accuracy rate depends on how well the feature functions are defined. In this project we have not implemented any part of speech (POS) tagger, so we are not able to take advantage of any knowledge about the grammar in the designing of feature functions. By doing that, and put more effort in the design of feature functions, it should be possible to get even higher accuracy rates.




\section*{Design and analysis of algorithms}
We present two different learning algorithms for learning Conditional Random Fields (CRF), which is a special case of Log Linear Models: Collins Perceptron and Contrastive Divergence. We begin by introducing the problem we apply the two algorithms to, followed by an explanation of each of the algorithms.

Both Collins Perceptron and Contrastive Divergence learn a set of weights $w$, which after training are used for prediction. In this project the set of weights are used for predicting punctuation marks for a given English sentence. More precisely, given a sequence of words $\bar x$, predict a sequence of tags $\bar y$, where tag $y_i$ is the punctuation mark after word x_i in sentence \bar x. Here, tag y_i is an element in the set of possible punctuation marks used in the English language, and the word x_i is a word in the English language. 

The problem of predicting the correct label for a given English sentence is formulated mathematically as: $\hat y = argmax \bar y p(\bar y | x; w$. I.e choose the label \hat y that has the highest probability given the sentence \bar x and the set of weighte $w$. If the number of different punctuation marks are $m$ and the length of the given sentence is $n$, there are $m^n$ different possible labels for that sentence. Going through all possible labels is intractible as it requires $O(m^n)$ time. Thus, we need a method that reduces the time complexity for solving the prediction problem.

In Log Linear Models the probability of $y$ given $x and w$ is: LIGNING FOR SSH FOR LOG LINEÃ†RE MODELLER HER.

Since the denominator is the same for every $y$ given $x and w$, we can look only at the numerator. We see that the numerator is the natural exponent raised to the power of a sum. This sum is proportional to the natural exponent raised to this sum, therefore we can look only at the sum in the numerator when evaluating the probability for different $y$ as $argmax FULLT UTTRYKK$ yields the same $\hat y$ as $argmax REDUSERT UTTRYKK$. 

To achieve tractability when solving the prediction problem we introduce the following restriction on the feature functions: $UTTRYKK FOR FEATURE FUNCTIONS HER$

As the next step in computing $\hat y$ in tractable time we define $UTTRYKK FOR g$. 
The expression for the probability of y given x and w now becomes:  $UTTRYKK FOR p(y|x;w)$ As we can see from the summations, we now sum $g_i$ for all positions $i$ in the sentence. As a preprocessing step in the prediction problem we compute $g_i$ for all positions $i$ and for every combinations of punctuation marks $y_(i-1) and y_i$. Recall that there are $m$ different punctuation marks. That means that there are $m^2$ different combinations of consequtive pairs of punctuation marks for a given position $i$. If there are $J$ different feature functions, computing the g-functions for all positions and every pair of punctuation marks, takes $O(n \cdot m^2 \cdot J)$ time and $O(n \cdot m^2)$ space. 

As the last step in achieving a reaonable time complexity for solving the prediction problem, we define $recursive expression for U(k, v)$. U(k, v) gives the most likely label of length $k$ where $y_k$ is locked to be $v$. Given U(k-1, y_k-1) and that the g-functions are calculated prior to this step, U(k, v) requires $O(m)$ time because we take the argmax over all possible tags in the recursive call. In the end U makes up a matrix where the element in row $i$ and column $v$ is the probability for the best label of length $i$ ending with the tag $v$. One can finally compute the most likely label $\bar y for the given sentence \bar x and set of weights w$ in the following way. $y_n$ is argmax v U(n, v), and $y_i$ is argmax v U(i-1, v) + g_i(v, y_i). Given the g-functions, the time complexity for solving the prediction problem is $O(m^2 \cdot n)$. In total, the time complexity for solving the prediction problem is $O(m^2 \cdot J \cdot n + m^2 \cdot n)$. Where the first term is for calculating the g-functions, and the latter term is for filling the U-matrix.  

Collins Perceptron is an alternative training method to Stochastic Gradient Following (SGF). Lik SGF, Collins Perceptron goes through all the examples in the training data once in whats referred to as an epoch. In each iteration of an epoch one example is drawn from the training examples, and the weights are updated according to an update rule. One of the ideas behind Collins Perceptron is to estimate the expectancy of $y'$ instead of calculating it exactly. The expectancy is: UTTRYKK FOR EXPECATANCY. The sum of probabilities over all y is equal to one, and the expectancy can thus be approximated as $F_j(x, \hat y)$, where $\hat y$ is the label with the highest probability, given the current model and sentence. What happens to $w_j$ in Collins Perceptron. When looking at the update rule we see that $wj$ increases if $F_j(x, y) > F_j(x, \hat y)$, and decreases if $F_j(x, y) < F_j(x, \hat y)$. It stays the same if $F_j(x, y) = F_j(x, \hat y)$. The resulting effect is that if the most probable label according to the current model is not the true label, we increase $w_j$ if $F_j$ yields a higher value for the true label than the most probable label. Conversly, if $F_j$ yields a higher value for the most probable label than the true label, we decrease $w_j$. Following this pattern, the weights is adjusted so that the true label gets more probable. 

Recall that the expression we use to evaluate the probability of label $y$ given sentence $x$ and weights $w$ is: UTTRYKK FOR SSH (SUM over g_i). To get the true label more probable we have to make its sum bigger. To make its sum bigger we have to emphasize the feature functions for which the true label has a higher value than the currently most probable label. Conversely, we have to decrease the weights corresponding to the feature functions for which the true label has a lower value than the currently most probable label. In this manner we make the true label more probable. Since the sum over all probabilities for every label $y-i$ has to be equal to one, this means that we also lower the probability for the labels not equal to the true label. 

Another difference between Colling Perceptron and SGF, is that in Collins Perceptron one use a learning rate $\alpha$ is equal to one. The reason for this is that, we only care about the most probable label $\hat y$ itself, not its probable. Which label that is most probable is not affected by the learnin rate, as long as the learning rate is constant. Thus, we can set the learning rate to be one in Collins Perceptron. 

The idea behind Contrastive Divergence is that instead of using the most probable label $\hat y$ t use in the update rule during training, one uses the true labels evil twin $y^*$. $y^*$ is a label that is similar to the true label, but has higher probability than the true label. Why use $y^*$ instead of $\hat y$? Finding $\hat y$ requires that we solve the prediction problem, which we showed earlier that can be computed in $O(n \cdot m^2 \cdot J + m^2 \cdot n)$. In the next section we show that finding $y^*$ requires less computation than solving the prediction problem, and thus improves our over all time complexity for learning (maybe a but vague). 

The way we find $y^*$ is to use Gibbs Sampling, which is introduces in this section. We want to draw random samples from the distribution (UTTRYKK FOR CONDITIONAL PROBABLITY HER). Suppose $\hat y = y1, y2, y3...yk$ Suppose that we can compute (PROBABILITY FOR Y1=v given x og y-i her) exactly numerically. Then we have the following algorithm to draw a random label from the distribution (UTTRYKK HER). ALGORITME HER. 

We can evaluate (UTTRYKK FOR SSH HER) using the following expression (ENDELIG UTTRYKK FOR GIBBS HER). This requires $O(m)$ time because we evaluate this expression for each punctuation mark. The total time to calculate $y^*$ is $O(m \cdot n)$ since there are $n$ tags in each label, given a sentence of length $n$. This assumes, however that the g-functions are already computed. The total time to find $y^*$ is then $O(n \cdot m^2 \cdot J + n \cdot m)$. We see that this requires less computation than solving the prediction problem. 

\section*{Experiments}

\subsection*{Design of Experiments}
The data set used for learning the model consisted of 70 115 English sentences. Both Collins' Perceptron and Gibbs sampling split those sentences into a training set and a validation set. The validation test is used after each epoch for determining the accuracy rate. Ratio of the training set compared to the validation set will be experimented with to see if that matters to the accuracy rate. In this implementation it is the same time complexity of the training and validation part, so the ratio should not affect the running time.

After the model was finished training it was tested on a different test set containing 28 027 English sentences. The accuracy rate was measured on the test set tag by tag. That means that the accuracy rate is the number of correct predicted tags in all sentences divided by number of total tags.

\subsection*{Results of Experiments}
Both classifiers was able to predict punctation on the test set with an accuracy of 93.95\%. Since the accuracy is measured on a tag by tag level, it is also interesting to see how good the accuracy is if you just assign space to all tags except the last one in a sentence where you assign period. This actually gives you a accuracy on 93.46\% on the test set. 


\section*{Findings and lessons learned}
The model learned is only able to predict 0.5\% better than a naive guess of spaces and periods. That means that the learner find it hard to predict other tags. It makes some correct predictions on question marks and commas, but this is only in the cases of question words for question marks, and conjunction words for commas. This is not happening often enough to improve the accuracy further. The other tags is hard to define by just looking at positions and words without knowing any grammar. It should be possible to write more feature functions that will be able to learn more with the grammar knowledge from POS tagging.




% Your references go at the end of the main text, and before the
% figures.  For this document we've used BibTeX, the .bib file
% scibib.bib, and the .bst file Science.bst.  The package scicite.sty
% was included to format the reference numbers according to *Science*
% style.


\bibliography{scibib}

\bibliographystyle{Science}




% For your review copy (i.e., the file you initially send in for
% evaluation), you can use the {figure} environment and the
% \includegraphics command to stream your figures into the text, placing
% all figures at the end.  For the final, revised manuscript for
% acceptance and production, however, PostScript or other graphics
% should not be streamed into your compliled file.  Instead, set
% captions as simple paragraphs (with a \noindent tag), setting them
% off from the rest of the text with a \clearpage as shown  below, and
% submit figures as separate files according to the Art Department's
% instructions.


\clearpage



\end{document}